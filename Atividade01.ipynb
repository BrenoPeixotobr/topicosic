{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Comparação entre três classificadores</h1></center>\n",
    "<p>Instituto Federal do Norte de Minas - IFNMG Montes Claros</p>\n",
    "<p><b>Curso:</b> Ciência da Computação</p>\n",
    "<p><b>Disciplina:</b> Tópicos em Inteligência Computacional</p>\n",
    "<p><b>Professora:</b> Luciana Balieiro Cosme</p>\n",
    "<p><b>Equipe:</b> Yoskoslowich S. N. Fernandes, Breno P. Santos e Daniel</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trabalho apresenta uma comparação entre três classificadores: MPLClassifier (perceptron multi-camda), KNN e Naive Bayes. A célula abaixo realiza a importanção dos três algoritmos, da base de dados e de outras ferramentas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn.metrics import classification_report, confusion_matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados utilizada foi a íris que contém 150 amostras; sendo 50 de cada um de três tipos diferentes de flores: setosa, versicolor, virginica. Cada amostra contém quatro características, que são: (1) comprimento da sépala, (2) largura da sépala, (3) comprimento da pétala e (4) largura da pétala; contudo apenas as duas primeiras foram utilizadas. Das 50 amostras de cada classe de flor, 40 foram usadas para treinamento e as outras 10 para testar o aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() # Carrega o dataset iris\n",
    "\n",
    "x = iris.data[:,:2] # Todas as 150 amostras, mas apenas as duas primeiras características\n",
    "y = iris.target # Classificação\n",
    "\n",
    "x_treino = numpy.concatenate( [ x[0:40, :], x[50:90, :], x[100:140, :] ] )\n",
    "x_teste = numpy.concatenate( [ x[40:50, :], x[90:100, :], x[140:150, :] ] )\n",
    "\n",
    "y_treino = numpy.concatenate( [ y[0:40], y[50:90], y[100:140] ] )\n",
    "y_teste = numpy.concatenate( [ y[40:50], y[90:100], y[140:150] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo os resultados do MPLClassifier. Ele classificou corretamente 25 das 30 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 2 2 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "[[ 9  1  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.71      1.00      0.83        10\n",
      "          2       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.90      0.87      0.87        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(alpha=0.01,max_iter=2000)\n",
    "clf.fit(x_treino, y_treino) \n",
    "\n",
    "y_previsto = clf.predict(x_teste)\n",
    "\n",
    "print(y_previsto)\n",
    "print(y_teste)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_teste,y_previsto))  \n",
    "print(\"\\n\")\n",
    "print(classification_report(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo os resultados do obtidos com o Naive Bayes. Ele classificou corretamente 26 das 30 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "[[ 9  1  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        10\n",
      "          1       0.71      1.00      0.83        10\n",
      "          2       1.00      0.70      0.82        10\n",
      "\n",
      "avg / total       0.90      0.87      0.87        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_treino, y_treino)\n",
    "\n",
    "y_previsto = clf.predict(x_teste)\n",
    "\n",
    "print(y_previsto)\n",
    "print(y_teste)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_teste,y_previsto))  \n",
    "print(\"\\n\")\n",
    "print(classification_report(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo os resultados do KNN. Ele classificou corretamente 23 das 30 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  6  4]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       0.60      0.90      0.72        10\n",
      "          2       0.80      0.40      0.53        10\n",
      "\n",
      "avg / total       0.80      0.77      0.75        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_treino, y_treino)\n",
    "\n",
    "y_previsto = clf.predict(x_teste)\n",
    "\n",
    "print(y_previsto)\n",
    "print(y_teste)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_teste,y_previsto))  \n",
    "print(\"\\n\")\n",
    "print(classification_report(y_teste,y_previsto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela abaixo apresenta o número de acertos de cada algoritmo por categoria de flor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>Tipo</td>\n",
    "        <td>MPLClassifier</td>\n",
    "        <td>Naive Bayes</td>\n",
    "        <td>KNN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>setosa</td>\n",
    "        <td>90%</td>\n",
    "        <td>90%</td>\n",
    "        <td>100%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>versicolor</td>\n",
    "        <td>100%</td>\n",
    "        <td>100%</td>\n",
    "        <td>90%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>virginica</td>\n",
    "        <td>70%</td>\n",
    "        <td>70%</td>\n",
    "        <td>40%</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
